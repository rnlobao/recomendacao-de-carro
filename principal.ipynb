{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from google_images_downloader import GoogleImagesDownloader\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sets iniciais de Dataset\n",
    "O que eu preciso?\n",
    "1) Um dataset que contém o id do usuário e um rating para um veículo, também com o ID dele\n",
    "2) Um dataset que contém o id do veículo com suas características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares\n",
    "\n",
    "def ler_csv_para_dataframe(caminho_arquivo_csv):\n",
    "    with open(caminho_arquivo_csv, 'r', newline='', encoding='utf-8') as arquivo_csv:\n",
    "        leitor_csv = csv.reader(arquivo_csv)\n",
    "        linhas = list(leitor_csv)        \n",
    "    df = pd.DataFrame(linhas[1:], columns=linhas[0])\n",
    "    return df\n",
    "    \n",
    "def renomear_arquivos_na_pasta(pasta, palavra_antiga, palavra_nova):\n",
    "    for nome_arquivo in os.listdir(pasta):\n",
    "        caminho_arquivo_antigo = os.path.join(pasta, nome_arquivo)\n",
    "        if palavra_antiga in nome_arquivo:\n",
    "            novo_nome_arquivo = nome_arquivo.replace(palavra_antiga, palavra_nova)\n",
    "            caminho_arquivo_novo = os.path.join(pasta, novo_nome_arquivo)\n",
    "            os.rename(caminho_arquivo_antigo, caminho_arquivo_novo)\n",
    "    print(\"Arquivos renomeados com sucesso!\")\n",
    "\n",
    "def obter_nomes_apos_substring(pasta):\n",
    "    nomes_extraidos = []\n",
    "    for nome_arquivo in os.listdir(pasta):\n",
    "        if \"Scraped_Car_Review_\" in nome_arquivo:\n",
    "            parte_nome = nome_arquivo.split(\"Scraped_Car_Review_\")[1].replace(\".csv\", \"\")\n",
    "            nomes_extraidos.append(parte_nome)\n",
    "    return nomes_extraidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento dos arquivos nas pastas\n",
    "\n",
    "pasta = './Data/'\n",
    "palavra_antiga = \"Reviews\"\n",
    "palavra_nova = \"Review\"\n",
    "renomear_arquivos_na_pasta(pasta, palavra_antiga, palavra_nova)\n",
    "\n",
    "palavra_antiga = \"Scrapped\"\n",
    "palavra_nova = \"Scraped\"\n",
    "renomear_arquivos_na_pasta(pasta, palavra_antiga, palavra_nova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dos datasets pegando quais carros tem em comum entre o dataset de consumidores e de veículos\n",
    "\n",
    "marcas_de_carro = obter_nomes_apos_substring(\"./Data/\")\n",
    "todos_df = []\n",
    "\n",
    "for marca in marcas_de_carro:\n",
    "    file_path = f'./Data/Scraped_Car_Review_{marca}.csv'\n",
    "    df = ler_csv_para_dataframe(file_path)\n",
    "    df = df.drop([\"Review_Title\", \"Review\", \"Review_Date\", \"\"], axis=1)\n",
    "    todos_df.append(df)\n",
    "\n",
    "ratings = pd.concat(todos_df, ignore_index=True)\n",
    "ratings = ratings.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Retirar o Author_Name e substituir por um ID unico para cada comprador\n",
    "\n",
    "author_to_id = {}\n",
    "for i, author in enumerate(ratings[\"Author_Name\"].unique()):\n",
    "    author_to_id[author] = i\n",
    "ratings[\"userID\"] = ratings[\"Author_Name\"].apply(lambda author: author_to_id[author])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Algumas tratativas do dataset\n",
    "\n",
    "ratings['Company'] = ratings['Vehicle_Title'].str.split().str[1]\n",
    "ratings['Vehicle_Title'] = ratings['Vehicle_Title'].str.split().str[2:]\n",
    "ratings['Vehicle_Title'] = ratings['Vehicle_Title'].str.join(' ')\n",
    "ratings['First_Word'] = ratings['Vehicle_Title'].str.split().str[0]\n",
    "ratings = ratings.rename(columns={'First_Word': 'Model'})\n",
    "ratings = ratings.drop(\"Vehicle_Title\", axis=1)\n",
    "\n",
    "ratings['carID'] = ratings['Company'].astype(str) + '-' + ratings['Model'].astype(str)\n",
    "number_of_unique_ids = ratings['carID'].nunique()\n",
    "\n",
    "cars = pd.read_csv('cars.csv')\n",
    "cars['carID'] = cars['Company'].astype(str) + '-' + cars['Model'].astype(str)\n",
    "\n",
    "# ratings.to_csv('ratings.csv')\n",
    "# cars.to_csv('df_cars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algumas análises estatísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings = len(ratings)\n",
    "n_cars = len(ratings['carID'].unique())\n",
    "n_users = len(ratings['userID'].unique())\n",
    "\n",
    "print(f\"Numero de ratings: {n_ratings}\")\n",
    "print(f\"Numero de veiculos unicos: {n_cars}\")\n",
    "print(f\"Numero de avaliadores unicos: {n_users}\")\n",
    "print(f\"Rating medio por avaliador: {round(n_ratings/n_users, 2)}\")\n",
    "print(f\"Numero medio de rating por veiculo: {round(n_ratings/n_cars, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['Rating'] = ratings['Rating'].astype(float)\n",
    "mean_rating = ratings.groupby('carID')[['Rating']].mean()\n",
    "lowest_rated = mean_rating['Rating'].idxmin()\n",
    "cars.loc[cars['carID'] == lowest_rated]\n",
    "highest_rated = mean_rating['Rating'].idxmax()\n",
    "cars.loc[cars['carID'] == highest_rated]\n",
    "ratings[ratings['carID']==highest_rated]\n",
    "ratings[ratings['carID']==lowest_rated]\n",
    "\n",
    "car_stats = ratings.groupby('carID')[['Rating']].agg(['count', 'mean'])\n",
    "car_stats.columns = car_stats.columns.droplevel()\n",
    "\n",
    "ratings.head()\n",
    "# cars.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(df):\n",
    "\t\n",
    "\tN = len(df['userID'].unique())\n",
    "\tM = len(df['carID'].unique())\n",
    "\t\n",
    "\tuser_mapper = dict(zip(np.unique(df[\"userID\"]), list(range(N))))\n",
    "\tcar_mapper = dict(zip(np.unique(df[\"carID\"]), list(range(M))))\n",
    "\t\n",
    "\tuser_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"userID\"])))\n",
    "\tcar_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"carID\"])))\n",
    "\t\n",
    "\tuser_index = [user_mapper[i] for i in df['userID']]\n",
    "\tcar_index = [car_mapper[i] for i in df['carID']]\n",
    "\n",
    "\tX = csr_matrix((df[\"Rating\"], (car_index, user_index)), shape=(M, N))\n",
    "\t\n",
    "\treturn X, user_mapper, car_mapper, user_inv_mapper, car_inv_mapper\n",
    "\t\n",
    "X, user_mapper, car_mapper, user_inv_mapper, car_inv_mapper = create_matrix(ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_movies(car_id, X, k, metric='euclidean', show_distance=False):\n",
    "\t\n",
    "\tneighbour_ids = []\n",
    "\t\n",
    "\tcar_ind = car_mapper[car_id]\n",
    "\tcar_vec = X[car_ind]\n",
    "\tk+=1\n",
    "\tkNN = NearestNeighbors(n_neighbors=k, algorithm=\"brute\", metric=metric)\n",
    "\tkNN.fit(X)\n",
    "\tcar_vec = car_vec.reshape(1,-1)\n",
    "\tneighbour = kNN.kneighbors(car_vec, return_distance=show_distance)\n",
    "\tfor i in range(0,k):\n",
    "\t\tn = neighbour.item(i)\n",
    "\t\tneighbour_ids.append(car_inv_mapper[n])\n",
    "\tneighbour_ids.pop(0)\n",
    "\treturn neighbour_ids\n",
    "\n",
    "\n",
    "car_titles = dict(zip(cars['carID'], cars['carID']))\n",
    "\n",
    "car_id = 'Mercury-Cougar'\n",
    "\n",
    "similar_ids = find_similar_movies(car_id, X, k=3)\n",
    "car_title = car_titles[car_id]\n",
    "\n",
    "for i in similar_ids:\n",
    "\tdownloader = GoogleImagesDownloader(browser=\"chrome\", show=False, debug=False, quiet=False, disable_safeui=False) \n",
    "\tdownloader.download(car_titles[i], limit=1, destination=\"./carros-sugeridos\")\n",
    "\tdownloader.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Como voce gostou de {car_title}, voce tambem pode gostar dos:\")\n",
    "image_path0 = f'./carros-sugeridos/{car_titles[similar_ids[0]]}/{car_titles[similar_ids[0]]}_0.jpg'\n",
    "image_path1 = f'./carros-sugeridos/{car_titles[similar_ids[1]]}/{car_titles[similar_ids[1]]}_0.jpg'\n",
    "image_path2 = f'./carros-sugeridos/{car_titles[similar_ids[2]]}/{car_titles[similar_ids[2]]}_0.jpg'\n",
    "\n",
    "# md = f'<img src = \"{image_path0}\" width=\"300px\">'\n",
    "x = 10\n",
    "\n",
    "expr = f\"'O valor de x é {x}'\"\n",
    "print(eval(expr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
